{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.19.1)\n",
      "Requirement already satisfied: markdownify in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: html2text in /usr/local/python/3.10.13/lib/python3.10/site-packages (2024.2.26)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /home/codespace/.local/lib/python3.10/site-packages (from markdownify) (4.12.3)\n",
      "Requirement already satisfied: six<2,>=1.15 in /home/codespace/.local/lib/python3.10/site-packages (from markdownify) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.10/site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets markdownify html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import html2text\n",
    "import markdownify\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "from datasets import Dataset\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.investopedia.com/\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_links = []\n",
    "def get_nav_links():\n",
    "    \"\"\"\n",
    "    Gets all the links from the navbar.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    nav_links = soup.find_all(\"li\", class_=\"header-nav__list-item\")\n",
    "    nav_top_links = []\n",
    "    for link in nav_links:\n",
    "        if \"simulator\" not in link.a[\"href\"] and \"academy\" not in link.a[\"href\"]:\n",
    "            nav_top_links.append(link.a[\"href\"])\n",
    "            top_links.append(link.a[\"href\"])\n",
    "    for link in nav_top_links:\n",
    "        response = requests.get(link, headers=headers)\n",
    "        soup_sublink = BeautifulSoup(response.text, \"html.parser\")\n",
    "        sub_links = soup_sublink.find_all(\"li\", class_=\"header-nav__sublist-item\")\n",
    "        for sub_link in sub_links:\n",
    "            if \"simulator\" not in sub_link.a[\"href\"] and \"academy\" not in sub_link.a[\"href\"]:\n",
    "                top_links.append(sub_link.a[\"href\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nav_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "morein_links = []\n",
    "def get_morein_links(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    morein_links_bottom = soup.find_all(\"a\", class_=\"mntl-taxonomysc-sibling-node mntl-text-link\")\n",
    "    for morein_link in morein_links_bottom:\n",
    "        morein_links.append(morein_link[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    executor.map(get_morein_links, top_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_links.extend(morein_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_links = list(set(top_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer_links = []\n",
    "def get_footer_links():\n",
    "    footer_links_btm = soup.find_all(\"li\", class_=\"comp terms-bar__item mntl-block\")\n",
    "    for link in footer_links_btm:\n",
    "        footer_links.append(link.a[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_footer_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faq_links(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    faq_links = soup.find_all(\"a\", class_=\"accordion-content__feature-link mntl-text-link\")\n",
    "    return list(set([link[\"href\"] for link in faq_links]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_term_links(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    key_term_links = soup.find_all(\"a\", class_=\"carousel-card__link mntl-text-link\")\n",
    "    return list(set([link[\"href\"] for link in key_term_links]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_links = []\n",
    "def get_article_links(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    links = soup.find_all('a', class_=\"comp mntl-card-list-items mntl-document-card mntl-card card card--no-image\")\n",
    "    if links:\n",
    "        faq_links = get_faq_links(url)\n",
    "        key_term_links = get_key_term_links(url)\n",
    "        article_links.extend(key_term_links + faq_links + list(set([link[\"href\"] for link in links])))\n",
    "    else:\n",
    "        footerlinks = soup.find_all(\"a\", class_=\"dictionary-top300-list__list mntl-text-link\")\n",
    "        article_links.extend([link[\"href\"] for link in footerlinks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    executor.map(get_article_links, top_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_links = list(set(article_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "def get_article_title(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    heading = soup.find(\"h1\", class_=\"article-heading\")\n",
    "    if heading:\n",
    "        titles.append(heading.text.strip())\n",
    "    else:\n",
    "        title = soup.find(\"title\")\n",
    "        titles.append(title.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in article_links:\n",
    "    try:\n",
    "        get_article_title(link)\n",
    "    except:\n",
    "        print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = []\n",
    "md_content = []\n",
    "clean_content = []\n",
    "def get_article_content(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    content = soup.find(\"div\", class_=\"comp mntl-sc-page mntl-block article-body-content\")\n",
    "    html_content.append(f\"{content}\")\n",
    "    md_content.append(markdownify.markdownify(f\"{content}\", heading_style=\"ATX\"))\n",
    "    clean_content.append(\" \".join([c.text for c in content]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in article_links:\n",
    "    try:\n",
    "        get_article_content(link)\n",
    "    except:\n",
    "        print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pd = {\n",
    "    \"url\": article_links,\n",
    "    \"title\": titles,\n",
    "    \"html_content\": html_content,\n",
    "    \"md_content\": md_content,\n",
    "    \"clean_content\": clean_content\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.push_to_hub(\"openvega-simon/investopedia\", private=True, token=True, max_shard_size=\"2GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
